{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine translation with RNNs\n",
    "\n",
    "In the previous lab, we have seen how to load and preprocess a text dataset, as well as the basics of RNNs. We also implemented the encoder of a machine translation network. In this lab, we code the decoder and the full model, and we train it on our dataset.\n",
    "\n",
    "<center><a href=\"https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\">\n",
    "    <img src=\"https://pytorch.org/tutorials/_images/seq2seq.png\" width=\"500\"></a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import spacy\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and preprocessing\n",
    "\n",
    "All the preprocessing part is the same as in the previous lab (except we also load a validation set), so we directly provide the code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# German and English specific pipelines\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Tokenizers\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# Fields\n",
    "SRC = Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "TRG = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "\n",
    "# Dataset\n",
    "train_data, valid_data, test_data = Multi30k.splits(root='data/', exts = ('.de', '.en'), fields = (SRC, TRG))\n",
    "\n",
    "# We take a subset of the full dataset for speed\n",
    "train_data.examples = train_data.examples[:1000]\n",
    "valid_data.examples = valid_data.examples[:100]\n",
    "test_data.examples = train_data.examples[:100]\n",
    "\n",
    "# Vocabulary\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)\n",
    "\n",
    "# Dataloader (here we keep the validation dataloader)\n",
    "batch_size = 128\n",
    "train_dataloader, valid_dataloader, test_dataloader = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index to string functions\n",
    "def indx2tokens_list(list_indx, field):\n",
    "    list_tokens = [field.vocab.itos[list_indx[i]] for i in range(len(list_indx))]\n",
    "    beg_i = list_tokens.index('<sos>')\n",
    "    if '<eos>' in list_tokens:\n",
    "        end_i = list_tokens.index('<eos>')\n",
    "    else:\n",
    "        end_i = -1\n",
    "    list_tokens = list_tokens[beg_i+1:end_i]\n",
    "    return list_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an example batch\n",
    "example_batch = next(iter(train_dataloader))\n",
    "example_batch_src, example_batch_trg = example_batch.src, example_batch.trg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq model\n",
    "\n",
    "Let's remind the overall structure of the machine translation model. This model is based on two parts:\n",
    "\n",
    "- an *encoder*, which takes as input the source sentence (in German) and encodes it into a *context* vector. This context vector is sort of a summary of the whole input sentence.\n",
    "- a *decoder*, which takes as input this context vector and sequentially generates a sentence in English. It always starts with the `<sos>` token and uses the context vector to generate the second token. Then, it recursively uses the last produced token and the hidden state to generate the next token.\n",
    "\n",
    "<center><a href=\"https://github.com/bentrevett/pytorch-seq2seq\">\n",
    "    <img src=\"https://github.com/bentrevett/pytorch-seq2seq/raw/49df8404d938a6edbf729876405558cc2c2b3013//assets/seq2seq1.png\"></a></center>\n",
    "\n",
    "\n",
    "### Encoder\n",
    "\n",
    "We provide the encoder below. It is very similar to the encoder written in lab 7, except it uses a 2-layer LSTM with recurrent dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, n_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(input_size, emb_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, n_layers, dropout=dropout_rate)\n",
    "        \n",
    "    def forward(self, src):\n",
    "                                            \n",
    "        y = self.embedding_layer(src)\n",
    "        y = self.dropout(y)\n",
    "        _, (hidden, cell) = self.lstm(y)\n",
    "                                            \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 62864\n",
      "torch.Size([2, 128, 50])\n",
      "torch.Size([2, 128, 50])\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "input_size = len(SRC.vocab)\n",
    "emb_size_enc = 32\n",
    "hidden_size = 50\n",
    "n_layers = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Instanciate the encoder and print the number of trainable parameters\n",
    "encoder_lstm = LSTMEncoder(input_size, emb_size_enc, hidden_size, n_layers, dropout_rate)\n",
    "print('Number of parameters:', sum(p.numel() for p in encoder_lstm.parameters()))\n",
    "\n",
    "# Apply it to the example batch\n",
    "enc_hidden, enc_cell = encoder_lstm(example_batch_src)\n",
    "print(enc_hidden.shape)\n",
    "print(enc_cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Now, let's build the decoder. We treat machine translation as a classification task: the decoder tries to predict the probability of all token indices in the output (target) vocabulary from an input token index. This has two implications:\n",
    "\n",
    "- In addition to the embedding, dropout and LSTM layers, the decoder applies an extra linear layer/MLP to perform prediction of the probabilities. Therefore, this linear layer goes from a space of size `hidden_size_dec` to a space of size `output_size`, which is the number of tokens in the target vocabulary.\n",
    "- the decoder doesn't process all the sentence at once, but instead it processes tokens one by one, since the input at step $t$ is the word that has been predicted at step $t-1$ (not just the hidden state). Therefore, the input to the decoder has a sequence length of 1 (the recursive calculation over the whole sentence will be done in the full model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, output_size, emb_size, hidden_size, n_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TO DO:\n",
    "        # - store the attributes\n",
    "        # - create the embedding, dropout, and LSTM layers (it uses recurrent dropout)\n",
    "        # - create the linear layer (it goes from a space of size 'hidden_size' to 'output_size')\n",
    "        self.output_size = output_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
    "        self.embedding_layer = nn.Embedding(output_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, n_layers,dropout=dropout_rate)\n",
    "        self.linear_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_idx, input_hidden, input_cell):\n",
    "        \n",
    "        # apply the embedding and dropout layers\n",
    "        y = self.dropout_layer(self.embedding_layer(input_idx))\n",
    "        \n",
    "        # since y has a shape [batch_size, hidden_size], we need to unsqueeze it\n",
    "        # to create an artificial 'seq_length' (=1) dimension\n",
    "        y = y.unsqueeze(0)\n",
    "        \n",
    "        # TO DO:\n",
    "        # - apply the LSTM layer. Unlike the encoder, we need to store all the outputs to predict the target token\n",
    "        # - squeeze 'output' (to remove the useless dimension 'seq_length'=1)\n",
    "        # - apply the linear layer to 'output' in order to predict the probabilities\n",
    "        # - return the predicted probabilities per token, and the hidden / cell states of the LSTM decoder\n",
    "        output, (hidden, cell) = self.lstm(y, (input_hidden, input_cell))\n",
    "        prediction = self.linear_layer(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 105509\n",
      "torch.Size([128, 823])\n",
      "torch.Size([2, 128, 50])\n",
      "torch.Size([2, 128, 50])\n"
     ]
    }
   ],
   "source": [
    "# Define the decoder parameters\n",
    "output_size = len(TRG.vocab)\n",
    "emb_size_dec = 32\n",
    "\n",
    "# Instanciate the decoder and print the number of trainable parameters\n",
    "decoder_lstm = LSTMDecoder(output_size, emb_size_dec, hidden_size, n_layers, dropout_rate)\n",
    "print('Number of parameters:', sum(p.numel() for p in decoder_lstm.parameters()))\n",
    "\n",
    "# Create an artificial numerized input token (input indices) with value '2'\n",
    "# (it corresponds to the 'start of sentence' or '<sos>' token)\n",
    "input_idx = torch.ones(batch_size).int() * 2\n",
    "# input_idx = torch.ones(batch_size).long() * 2   # depending on your torch version, it might be 'long()' instead of 'int()'\n",
    "\n",
    "# Apply the decoder to this input token using the output of the encoder (hidden and cell)\n",
    "pred_proba, dec_hidden, dec_cell = decoder_lstm(input_idx, enc_hidden, enc_cell)\n",
    "print(pred_proba.shape)\n",
    "print(dec_hidden.shape)\n",
    "print(dec_cell.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'train',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'golf',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'big',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'firefighters',\n",
       " 'his',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'big',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'ride',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'pot',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'beside',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'beside',\n",
       " 'firefighters',\n",
       " 'train',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'ride',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'big',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'firefighters',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'ride',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'train',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'firefighters',\n",
       " 'slowly',\n",
       " 'scene',\n",
       " 'slowly',\n",
       " 'slowly',\n",
       " 'scene']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: from the predicted probabilities calculated before 'pred_proba', get the index with the highest probability\n",
    "\n",
    "# TO DO: for each element in the batch, transform this index back to an actual token (word)\n",
    "index_token = pred_proba.argmax(1)\n",
    "token = [TRG.vocab.itos[index_token[i]] for i in range(len(index_token))]\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model\n",
    "\n",
    "Finally, we need to implement the overall model, which takes an input sentence, produces the context vectors using the encoder, and produces the output sentence recursively using the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store the encoder, decoder, and the target vocabulary size\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.trg_vocab_size = decoder.output_size\n",
    "        \n",
    "    def forward(self, src, trg_len):\n",
    "        \n",
    "        # Create a tensor to store the predicted probabilities from the decoder\n",
    "        batch_size = src.shape[-1]\n",
    "        pred_probas_all = torch.zeros(trg_len, batch_size, self.trg_vocab_size)\n",
    "        \n",
    "        # Assign a probability of 1 to the token corresponding to <sos> for the first element\n",
    "        pred_probas_all[0, :, 2] = 1\n",
    "        \n",
    "        # Initialize the first input to the decoder as the <sos> token (coded by '2' in our vocabulary)\n",
    "        input_idx = torch.ones(batch_size).int() * 2\n",
    "        \n",
    "        # TO DO: apply the encoder to the src sentence and get the last hidden and cell states (=context vectors)\n",
    "        # (these will be used as initial hidden/cell for the decoder)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # loop over tokens (note that it starts from 1 -not 0- since the very first token is already known (=<sos>))\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            # TO DO:\n",
    "            # - apply the decoder to get the predicted probabilites of the token t (and the updated hidden/cell)\n",
    "            # - store these predicted probabilities in the 'pred_probas_all' tensor\n",
    "            # - get the index corresponding to the highest probability for this token: it will be used as the next input index\n",
    "            output, hidden, cell = self.decoder(input_idx, hidden, cell)\n",
    "            input_idx = output.argmax(1)\n",
    "            pred_probas_all[t,:,:] = output\n",
    "        return pred_probas_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the LSTM model: 168373\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Instanciate the model and print the number of parameters\n",
    "encoder_lstm = LSTMEncoder(input_size, emb_size_enc, hidden_size, n_layers, dropout_rate)\n",
    "decoder_lstm = LSTMDecoder(output_size, emb_size_dec, hidden_size, n_layers, dropout_rate)\n",
    "model_lstm = LSTMSeq2Seq(encoder_lstm, decoder_lstm)\n",
    "print('Number of parameters in the LSTM model:', sum(p.numel() for p in model_lstm.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Q1**</span> How many parameters are in the LSTM Seq2seq model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jogging',\n",
       " 'boxes',\n",
       " 'road',\n",
       " 'boxes',\n",
       " 'boxes',\n",
       " 'beach',\n",
       " 'road',\n",
       " 'road',\n",
       " 'beach',\n",
       " 'boxes',\n",
       " 'boxes',\n",
       " 'set',\n",
       " 'set',\n",
       " 'boxes',\n",
       " 'adults',\n",
       " 'adults',\n",
       " 'dock',\n",
       " 'beach',\n",
       " 'set',\n",
       " 'set',\n",
       " 'set',\n",
       " 'set',\n",
       " 'set']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Apply the model to the 'example_batch'\n",
    "\n",
    "# TO DO: Get the indices of highest predicted probabilities\n",
    "\n",
    "# TO DO: Take one sample from the batch of predicted indices, and transform it back to tokens (use the indx2tokens_list function)\n",
    "example_batch_src, example_batch_trg = example_batch.src, example_batch.trg\n",
    "trg_len = example_batch_trg.shape[0]\n",
    "probas = model_lstm(example_batch_src, trg_len)\n",
    "out_probas = probas.argmax(2)\n",
    "out_probas.shape\n",
    "indx2tokens_list(out_probas[:,0], TRG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation\n",
    "\n",
    "Now we have our model implemented, we can train it. We provide the evaluation and training with validation functions (they are very similar to what was done in previous labs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_seq2seq(model, eval_dataloader, loss_fn, SEED = 1234):\n",
    "\n",
    "    # Set a random seed for reproducibility\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    # Set the model in 'eval' mode (disable dropout layer)\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize the eval loss\n",
    "    loss_eval = 0\n",
    "\n",
    "    # loop over batches\n",
    "    for i, batch in enumerate(eval_dataloader):\n",
    "\n",
    "        # Get the source and target sentence, and the target length, copy it to device\n",
    "        src, trg = batch.src, batch.trg\n",
    "        trg_len = trg.shape[0]\n",
    "\n",
    "        # Apply the model\n",
    "        pred_probas = model(src, trg_len)\n",
    "\n",
    "        # Remove the first token (always <sos>) to compute the loss\n",
    "        output_size = pred_probas.shape[-1]\n",
    "        pred_probas = pred_probas[1:]\n",
    "\n",
    "        # Reshape the pred_probas and target so that they have appropriate shapes:\n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output_size]\n",
    "        pred_probas = pred_probas.view(-1, output_size)\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(pred_probas, trg)\n",
    "\n",
    "        # Record the loss\n",
    "        loss_eval += loss.item()\n",
    "\n",
    "    return loss_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_val_seq2seq(model, train_dataloader, valid_dataloader, num_epochs, loss_fn, learning_rate, verbose=True, SEED = 1234):\n",
    "\n",
    "    # Set a random seed for reproducibility\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    # Make a copy of the model (avoid changing the model outside this function)\n",
    "    model_tr = copy.deepcopy(model)\n",
    "    \n",
    "    # Set the model in 'training' mode (ensures all parameters' gradients are computed)\n",
    "    model_tr.train()\n",
    "\n",
    "    # define the optimizer (Adam)\n",
    "    optimizer = torch.optim.SGD(model_tr.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Initialize lists for storing the train and val losses\n",
    "    loss_train_total = []\n",
    "    loss_val_total = []\n",
    "    \n",
    "    loss_val_optim = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        loss_current_epoch = 0\n",
    "\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Get the source and target sentence, and the target length, copy it to device\n",
    "            src, trg = batch.src, batch.trg\n",
    "            trg_len = trg.shape[0]\n",
    "\n",
    "            # Set the gradients at 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Apply the model\n",
    "            pred_probas = model_tr(src, trg_len)\n",
    "\n",
    "            # Remove the first token (always <sos>) to compute the loss\n",
    "            output_dim = pred_probas.shape[-1]\n",
    "            pred_probas = pred_probas[1:]\n",
    "\n",
    "            # Reshape the pred_probas and target\n",
    "            pred_probas = pred_probas.view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss = loss_fn(pred_probas, trg)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model_tr.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Record the loss\n",
    "            loss_current_epoch += loss.item()\n",
    "\n",
    "        # At the end of each epoch, compute the validation loss\n",
    "        loss_val = evaluate_seq2seq(model_tr, valid_dataloader, loss_fn)\n",
    "        \n",
    "        # Record the training and validation losss over epochs\n",
    "        loss_train_total.append(loss_current_epoch)\n",
    "        loss_val_total.append(loss_val)\n",
    "        \n",
    "        # Display the training and validation losses\n",
    "        if verbose:\n",
    "            print('Epoch [{}/{}], Training loss: {:.4f} ; Validation loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, loss_current_epoch, loss_val))\n",
    "            \n",
    "        # Save the current model as optimal only if validation loss decreases\n",
    "        if loss_val<loss_val_optim:\n",
    "            model_opt = copy.deepcopy(model_tr)\n",
    "            loss_val_optim = loss_val\n",
    "                \n",
    "    return model_opt, loss_train_total, loss_val_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training loss: 53.5203 ; Validation loss: 6.6906\n",
      "Epoch [2/50], Training loss: 53.5001 ; Validation loss: 6.6857\n",
      "Epoch [3/50], Training loss: 53.4655 ; Validation loss: 6.6807\n",
      "Epoch [4/50], Training loss: 53.4300 ; Validation loss: 6.6757\n",
      "Epoch [5/50], Training loss: 53.3938 ; Validation loss: 6.6707\n",
      "Epoch [6/50], Training loss: 53.3595 ; Validation loss: 6.6656\n",
      "Epoch [7/50], Training loss: 53.3213 ; Validation loss: 6.6611\n",
      "Epoch [8/50], Training loss: 53.2843 ; Validation loss: 6.6556\n",
      "Epoch [9/50], Training loss: 53.2474 ; Validation loss: 6.6505\n",
      "Epoch [10/50], Training loss: 53.2111 ; Validation loss: 6.6453\n",
      "Epoch [11/50], Training loss: 53.1741 ; Validation loss: 6.6401\n",
      "Epoch [12/50], Training loss: 53.1319 ; Validation loss: 6.6341\n",
      "Epoch [13/50], Training loss: 53.0943 ; Validation loss: 6.6288\n",
      "Epoch [14/50], Training loss: 53.0570 ; Validation loss: 6.6235\n",
      "Epoch [15/50], Training loss: 53.0203 ; Validation loss: 6.6182\n",
      "Epoch [16/50], Training loss: 52.9823 ; Validation loss: 6.6128\n",
      "Epoch [17/50], Training loss: 52.9437 ; Validation loss: 6.6074\n",
      "Epoch [18/50], Training loss: 52.9065 ; Validation loss: 6.6019\n",
      "Epoch [19/50], Training loss: 52.8666 ; Validation loss: 6.5965\n",
      "Epoch [20/50], Training loss: 52.8290 ; Validation loss: 6.5909\n",
      "Epoch [21/50], Training loss: 52.7885 ; Validation loss: 6.5854\n",
      "Epoch [22/50], Training loss: 52.7494 ; Validation loss: 6.5798\n",
      "Epoch [23/50], Training loss: 52.7097 ; Validation loss: 6.5741\n",
      "Epoch [24/50], Training loss: 52.6699 ; Validation loss: 6.5684\n",
      "Epoch [25/50], Training loss: 52.6282 ; Validation loss: 6.5627\n",
      "Epoch [26/50], Training loss: 52.5879 ; Validation loss: 6.5569\n",
      "Epoch [27/50], Training loss: 52.5480 ; Validation loss: 6.5510\n",
      "Epoch [28/50], Training loss: 52.5070 ; Validation loss: 6.5451\n",
      "Epoch [29/50], Training loss: 52.4642 ; Validation loss: 6.5391\n",
      "Epoch [30/50], Training loss: 52.4222 ; Validation loss: 6.5331\n",
      "Epoch [31/50], Training loss: 52.3787 ; Validation loss: 6.5270\n",
      "Epoch [32/50], Training loss: 52.3346 ; Validation loss: 6.5208\n",
      "Epoch [33/50], Training loss: 52.2928 ; Validation loss: 6.5146\n",
      "Epoch [34/50], Training loss: 52.2481 ; Validation loss: 6.5083\n",
      "Epoch [35/50], Training loss: 52.2034 ; Validation loss: 6.5019\n",
      "Epoch [36/50], Training loss: 52.1574 ; Validation loss: 6.4954\n",
      "Epoch [37/50], Training loss: 52.1124 ; Validation loss: 6.4889\n",
      "Epoch [38/50], Training loss: 52.0647 ; Validation loss: 6.4822\n",
      "Epoch [39/50], Training loss: 52.0173 ; Validation loss: 6.4755\n",
      "Epoch [40/50], Training loss: 51.9717 ; Validation loss: 6.4687\n",
      "Epoch [41/50], Training loss: 51.9233 ; Validation loss: 6.4618\n",
      "Epoch [42/50], Training loss: 51.8731 ; Validation loss: 6.4547\n",
      "Epoch [43/50], Training loss: 51.8217 ; Validation loss: 6.4476\n",
      "Epoch [44/50], Training loss: 51.7715 ; Validation loss: 6.4404\n",
      "Epoch [45/50], Training loss: 51.7192 ; Validation loss: 6.4330\n",
      "Epoch [46/50], Training loss: 51.6676 ; Validation loss: 6.4256\n",
      "Epoch [47/50], Training loss: 51.6147 ; Validation loss: 6.4180\n",
      "Epoch [48/50], Training loss: 51.5597 ; Validation loss: 6.4103\n",
      "Epoch [49/50], Training loss: 51.5067 ; Validation loss: 6.4025\n",
      "Epoch [50/50], Training loss: 51.4504 ; Validation loss: 6.3945\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50\n",
    "\n",
    "# For the loss function, since we treat the problem as a classification task, we use the cross entropy.\n",
    "# We also tell it to ignore the index of the <pad> token for computation speed\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "# Training\n",
    "model_lstm, loss_train_lstm, loss_val_lstm = training_val_seq2seq(model_lstm, train_dataloader, valid_dataloader, num_epochs, loss_fn, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU network\n",
    "\n",
    "Let us consider an alternative architecture using GRU instead of LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: write the GRU encoder, decoder, and full seq2seq model. Most of the previous LSTM-related code can be reused.\n",
    "# Remember that a GRU only has two outputs ('out' and 'hidden'), unlike LSTM which has an additional 'cell'.\n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, n_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(input_size, emb_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.lstm = nn.GRU(emb_size, hidden_size, n_layers, dropout=dropout_rate)\n",
    "        \n",
    "    def forward(self, src):\n",
    "                                            \n",
    "        y = self.embedding_layer(src)\n",
    "        y = self.dropout(y)\n",
    "        _, cell = self.lstm(y)\n",
    "                                            \n",
    "        return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 53564\n",
      "torch.Size([2, 128, 50])\n"
     ]
    }
   ],
   "source": [
    "input_size = len(SRC.vocab)\n",
    "emb_size_enc = 32\n",
    "hidden_size = 50\n",
    "n_layers = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Instanciate the encoder and print the number of trainable parameters\n",
    "encoder_gru = GRUEncoder(input_size, emb_size_enc, hidden_size, n_layers, dropout_rate)\n",
    "print('Number of parameters:', sum(p.numel() for p in encoder_lstm.parameters()))\n",
    "\n",
    "# Apply it to the example batch\n",
    "enc_hidden = encoder_gru(example_batch_src)\n",
    "print(enc_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, output_size, emb_size, hidden_size, n_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TO DO:\n",
    "        # - store the attributes\n",
    "        # - create the embedding, dropout, and LSTM layers (it uses recurrent dropout)\n",
    "        # - create the linear layer (it goes from a space of size 'hidden_size' to 'output_size')\n",
    "        self.output_size = output_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
    "        self.embedding_layer = nn.Embedding(output_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, n_layers,dropout=dropout_rate)\n",
    "        self.linear_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_idx, input_cell):\n",
    "        \n",
    "        # apply the embedding and dropout layers\n",
    "        y = self.dropout_layer(self.embedding_layer(input_idx))\n",
    "        \n",
    "        # since y has a shape [batch_size, hidden_size], we need to unsqueeze it\n",
    "        # to create an artificial 'seq_length' (=1) dimension\n",
    "        y = y.unsqueeze(0)\n",
    "        \n",
    "        # TO DO:\n",
    "        # - apply the LSTM layer. Unlike the encoder, we need to store all the outputs to predict the target token\n",
    "        # - squeeze 'output' (to remove the useless dimension 'seq_length'=1)\n",
    "        # - apply the linear layer to 'output' in order to predict the probabilities\n",
    "        # - return the predicted probabilities per token, and the hidden / cell states of the LSTM decoder\n",
    "        output,  cell = self.gru(y, input_cell)\n",
    "        prediction = self.linear_layer(output.squeeze(0))\n",
    "        return prediction, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 96209\n",
      "torch.Size([128, 50])\n",
      "torch.Size([128, 823])\n",
      "torch.Size([2, 128, 50])\n"
     ]
    }
   ],
   "source": [
    "# Define the decoder parameters\n",
    "output_size = len(TRG.vocab)\n",
    "emb_size_dec = 32\n",
    "\n",
    "# Instanciate the decoder and print the number of trainable parameters\n",
    "decoder_gru = GRUDecoder(output_size, emb_size_dec, hidden_size, n_layers, dropout_rate)\n",
    "print('Number of parameters:', sum(p.numel() for p in decoder_lstm.parameters()))\n",
    "\n",
    "# Create an artificial numerized input token (input indices) with value '2'\n",
    "# (it corresponds to the 'start of sentence' or '<sos>' token)\n",
    "input_idx = torch.ones(batch_size).int() * 2\n",
    "# input_idx = torch.ones(batch_size).long() * 2   # depending on your torch version, it might be 'long()' instead of 'int()'\n",
    "print(enc_cell.shape)\n",
    "# Apply the decoder to this input token using the output of the encoder (hidden and cell)\n",
    "pred_proba, dec_cell = decoder_gru(input_idx, enc_hidden)\n",
    "print(pred_proba.shape)\n",
    "print(dec_cell.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store the encoder, decoder, and the target vocabulary size\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.trg_vocab_size = decoder.output_size\n",
    "        \n",
    "    def forward(self, src, trg_len):\n",
    "        \n",
    "        # Create a tensor to store the predicted probabilities from the decoder\n",
    "        batch_size = src.shape[-1]\n",
    "        pred_probas_all = torch.zeros(trg_len, batch_size, self.trg_vocab_size)\n",
    "        \n",
    "        # Assign a probability of 1 to the token corresponding to <sos> for the first element\n",
    "        pred_probas_all[0, :, 2] = 1\n",
    "        \n",
    "        # Initialize the first input to the decoder as the <sos> token (coded by '2' in our vocabulary)\n",
    "        input_idx = torch.ones(batch_size).int() * 2\n",
    "        \n",
    "        # TO DO: apply the encoder to the src sentence and get the last hidden and cell states (=context vectors)\n",
    "        # (these will be used as initial hidden/cell for the decoder)\n",
    "        cell = self.encoder(src)\n",
    "        \n",
    "        # loop over tokens (note that it starts from 1 -not 0- since the very first token is already known (=<sos>))\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            # TO DO:\n",
    "            # - apply the decoder to get the predicted probabilites of the token t (and the updated hidden/cell)\n",
    "            # - store these predicted probabilities in the 'pred_probas_all' tensor\n",
    "            # - get the index corresponding to the highest probability for this token: it will be used as the next input index\n",
    "            output, cell = self.decoder(input_idx, cell)\n",
    "            input_idx = output.argmax(1)\n",
    "            pred_probas_all[t,:,:] = output\n",
    "        return pred_probas_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the GRU model: 149773\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Instanciate the GRU model\n",
    "encoder_gru = GRUEncoder(input_size, emb_size_enc, hidden_size, n_layers, dropout_rate)\n",
    "decoder_gru = GRUDecoder(output_size, emb_size_dec, hidden_size, n_layers, dropout_rate)\n",
    "model_gru = GRUSeq2Seq(encoder_gru, decoder_gru)\n",
    "\n",
    "# Number of parameters\n",
    "print('Number of parameters in the GRU model:', sum(p.numel() for p in model_gru.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Q2**</span> How many parameters are in the GRU Seq2seq model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 128, 823])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: pass the example batch to the GRU model and print the size of the output ('pred_probas_all')\n",
    "example_batch_src, example_batch_trg = example_batch.src, example_batch.trg\n",
    "trg_len = example_batch_trg.shape[0]\n",
    "probas = model_gru(example_batch_src, trg_len)\n",
    "out_probas = probas.argmax(2)\n",
    "print(probas.shape)\n",
    "indx2tokens_list(out_probas[:,0], TRG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training loss: 53.7499 ; Validation loss: 6.7231\n",
      "Epoch [2/50], Training loss: 53.7045 ; Validation loss: 6.7070\n",
      "Epoch [3/50], Training loss: 53.6184 ; Validation loss: 6.6949\n",
      "Epoch [4/50], Training loss: 53.5572 ; Validation loss: 6.6861\n",
      "Epoch [5/50], Training loss: 53.5126 ; Validation loss: 6.6818\n",
      "Epoch [6/50], Training loss: 53.4773 ; Validation loss: 6.6827\n",
      "Epoch [7/50], Training loss: 53.4030 ; Validation loss: 6.6665\n",
      "Epoch [8/50], Training loss: 53.3428 ; Validation loss: 6.6632\n",
      "Epoch [9/50], Training loss: 53.2746 ; Validation loss: 6.6445\n",
      "Epoch [10/50], Training loss: 53.2574 ; Validation loss: 6.6513\n",
      "Epoch [11/50], Training loss: 53.1942 ; Validation loss: 6.6406\n",
      "Epoch [12/50], Training loss: 53.1265 ; Validation loss: 6.6314\n",
      "Epoch [13/50], Training loss: 53.0628 ; Validation loss: 6.6229\n",
      "Epoch [14/50], Training loss: 52.9929 ; Validation loss: 6.6144\n",
      "Epoch [15/50], Training loss: 52.9238 ; Validation loss: 6.6007\n",
      "Epoch [16/50], Training loss: 52.8752 ; Validation loss: 6.5957\n",
      "Epoch [17/50], Training loss: 52.8056 ; Validation loss: 6.5889\n",
      "Epoch [18/50], Training loss: 52.7370 ; Validation loss: 6.5764\n",
      "Epoch [19/50], Training loss: 52.6711 ; Validation loss: 6.5666\n",
      "Epoch [20/50], Training loss: 52.6103 ; Validation loss: 6.5633\n",
      "Epoch [21/50], Training loss: 52.5810 ; Validation loss: 6.5540\n",
      "Epoch [22/50], Training loss: 52.5083 ; Validation loss: 6.5465\n",
      "Epoch [23/50], Training loss: 52.4242 ; Validation loss: 6.5294\n",
      "Epoch [24/50], Training loss: 52.2804 ; Validation loss: 6.5085\n",
      "Epoch [25/50], Training loss: 52.1240 ; Validation loss: 6.5012\n",
      "Epoch [26/50], Training loss: 52.1071 ; Validation loss: 6.4902\n",
      "Epoch [27/50], Training loss: 51.9997 ; Validation loss: 6.4724\n",
      "Epoch [28/50], Training loss: 51.8444 ; Validation loss: 6.4459\n",
      "Epoch [29/50], Training loss: 51.6732 ; Validation loss: 6.4255\n",
      "Epoch [30/50], Training loss: 51.4988 ; Validation loss: 6.3972\n",
      "Epoch [31/50], Training loss: 51.3075 ; Validation loss: 6.3713\n",
      "Epoch [32/50], Training loss: 51.1178 ; Validation loss: 6.3419\n",
      "Epoch [33/50], Training loss: 50.9050 ; Validation loss: 6.3115\n",
      "Epoch [34/50], Training loss: 50.6860 ; Validation loss: 6.2792\n",
      "Epoch [35/50], Training loss: 50.4616 ; Validation loss: 6.2450\n",
      "Epoch [36/50], Training loss: 50.2128 ; Validation loss: 6.2068\n",
      "Epoch [37/50], Training loss: 49.9393 ; Validation loss: 6.1659\n",
      "Epoch [38/50], Training loss: 49.6540 ; Validation loss: 6.1200\n",
      "Epoch [39/50], Training loss: 49.3402 ; Validation loss: 6.0759\n",
      "Epoch [40/50], Training loss: 49.0152 ; Validation loss: 6.0304\n",
      "Epoch [41/50], Training loss: 48.6944 ; Validation loss: 5.9839\n",
      "Epoch [42/50], Training loss: 48.3796 ; Validation loss: 5.9365\n",
      "Epoch [43/50], Training loss: 48.0334 ; Validation loss: 5.8881\n",
      "Epoch [44/50], Training loss: 47.6996 ; Validation loss: 5.8392\n",
      "Epoch [45/50], Training loss: 47.3534 ; Validation loss: 5.7899\n",
      "Epoch [46/50], Training loss: 47.0107 ; Validation loss: 5.7405\n",
      "Epoch [47/50], Training loss: 46.6692 ; Validation loss: 5.6914\n",
      "Epoch [48/50], Training loss: 46.3359 ; Validation loss: 5.6430\n",
      "Epoch [49/50], Training loss: 45.9897 ; Validation loss: 5.5957\n",
      "Epoch [50/50], Training loss: 45.6795 ; Validation loss: 5.5498\n"
     ]
    }
   ],
   "source": [
    "# TO DO: train the GRU model\n",
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50\n",
    "\n",
    "# For the loss function, since we treat the problem as a classification task, we use the cross entropy.\n",
    "# We also tell it to ignore the index of the <pad> token for computation speed\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "# Training\n",
    "model_gru, loss_train_gru, loss_val_gru = training_val_seq2seq(model_gru, train_dataloader, \n",
    "                            valid_dataloader, \n",
    "                            num_epochs, loss_fn, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Comparing the LSTM and GRU models\n",
    "\n",
    "Finally, let us compare the two proposed architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the LSTM model: 168373\n",
      "Number of parameters in the GRU model: 149773\n"
     ]
    }
   ],
   "source": [
    "# TO DO: print the number of parameters of both models (already done above)\n",
    "print('Number of parameters in the LSTM model:', sum(p.numel() for p in model_lstm.parameters()))\n",
    "print('Number of parameters in the GRU model:', sum(p.numel() for p in model_gru.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO DO: plot the training and validation losses for both models\n",
    "# - one subplot will contain the training loss\n",
    "# - the other subplot represents the validation loss\n",
    "plt.figure(figsize=(10,10))\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=\"col\")\n",
    "ax1.plot(range(num_epochs),loss_train_lstm, label=\"LSTM\")\n",
    "ax1.plot(range(num_epochs), loss_train_gru, label=\"GRU\")\n",
    "ax1.set(xlabel='Number of epoch', ylabel='Loss',\n",
    "       title='Loss of the training')\n",
    "ax1.legend()\n",
    "f.tight_layout(pad=1.5)\n",
    "ax2.plot(range(num_epochs), loss_val_lstm,label=\"LSTM\")\n",
    "ax2.plot(range(num_epochs), loss_val_gru, label=\"GRU\")\n",
    "ax2.set(xlabel='Number of epoch', ylabel='Loss',\n",
    "       title='Loss of the testing')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Loss : 6.424\n",
      "GRU Loss : 5.676\n"
     ]
    }
   ],
   "source": [
    "#Â TO DO: compute and print the test loss for both models\n",
    "print(f\"LSTM Loss : {evaluate_seq2seq(model_lstm, test_dataloader, loss_fn, SEED = 1234):0.3f}\")\n",
    "print(f\"GRU Loss : {evaluate_seq2seq(model_gru, test_dataloader, loss_fn, SEED = 1234):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Q3**</span> Place these results (number of parameters, training log, and test loss) in your report. Based on these, which network would you recommend to use?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e4653ef3f08bbcc46c48a23d8290ce23ff8798f7d85b3da9ffbf3074ca96bd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
